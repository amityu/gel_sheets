{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bbc82f88581622",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:44:49.124954Z",
     "start_time": "2024-06-22T14:44:49.121972Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Compute Image Embeddings 2D.:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Compute Image Embeddings 2D.: 100%|██████████| 1/1 [00:25<00:00, 25.06s/it]\u001B[A\n",
      "Precompute state for files:  20%|██        | 1/5 [00:25<01:40, 25.09s/it]\n",
      "Compute Image Embeddings 2D.:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Compute Image Embeddings 2D.: 100%|██████████| 1/1 [00:23<00:00, 23.40s/it]\u001B[A\n",
      "Precompute state for files:  40%|████      | 2/5 [00:48<01:12, 24.10s/it]\n",
      "Compute Image Embeddings 2D.:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Compute Image Embeddings 2D.: 100%|██████████| 1/1 [00:23<00:00, 23.44s/it]\u001B[A\n",
      "Precompute state for files:  60%|██████    | 3/5 [01:11<00:47, 23.80s/it]\n",
      "Compute Image Embeddings 2D.:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Compute Image Embeddings 2D.: 100%|██████████| 1/1 [00:23<00:00, 23.35s/it]\u001B[A\n",
      "Precompute state for files:  80%|████████  | 4/5 [01:35<00:23, 23.63s/it]\n",
      "Compute Image Embeddings 2D.:   0%|          | 0/1 [00:00<?, ?it/s]\u001B[A\n",
      "Compute Image Embeddings 2D.: 100%|██████████| 1/1 [00:23<00:00, 23.15s/it]\u001B[A\n",
      "Precompute state for files: 100%|██████████| 5/5 [01:58<00:00, 23.69s/it]\n",
      "WARNING: DirectWrite: CreateFontFaceFromHDC() failed (Indicates an error in an input file such as a font file.) for QFontDef(Family=\"\", pointsize=12, pixelsize=16, styleHint=5, weight=50, stretch=100, hintingPreference=0) LOGFONT(\"MS Sans Serif\", lfWidth=0, lfHeight=-16) dpi=168\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from micro_sam.sam_annotator import image_folder_annotator\n",
    "from micro_sam.sample_data import fetch_image_series_example_data\n",
    "from micro_sam.util import get_cache_directory\n",
    "\n",
    "DATA_CACHE = os.path.join(get_cache_directory(), \"for yuval\")\n",
    "#EMBEDDING_CACHE = os.path.join(get_cache_directory(), \"embeddings\")\n",
    "EMBEDDING_CACHE = r'C:\\Users\\amityu\\Gel_Drop_Data\\yuval_embedding'\n",
    "os.makedirs(EMBEDDING_CACHE, exist_ok=True)\n",
    "\n",
    "\n",
    "def series_annotation(use_finetuned_model):\n",
    "    \"\"\"Annotate a series of images. Example runs for three different images.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_finetuned_model:\n",
    "        embedding_path = os.path.join(EMBEDDING_CACHE, \"series-embeddings-vit_b_lm\")\n",
    "        model_type = \"vit_b_lm\"\n",
    "    else:\n",
    "        embedding_path = os.path.join(EMBEDDING_CACHE, \"series-embeddings\")\n",
    "        model_type = \"vit_h\"\n",
    "\n",
    "    #example_data = fetch_image_series_example_data(DATA_CACHE)\n",
    "    example_data = r'C:\\Users\\amityu\\Gel_Drop_Data\\for_yuval_small'\n",
    "    image_folder_annotator(\n",
    "        example_data, \"./series-segmentation-result\",\n",
    "        pattern=\"*.tif\",\n",
    "        embedding_path=embedding_path,\n",
    "        model_type=model_type,\n",
    "        precompute_amg_state=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Whether to use the fine-tuned SAM model.\n",
    "    use_finetuned_model = False\n",
    "    series_annotation(use_finetuned_model)\n",
    "\n",
    "\n",
    "# The corresponding CLI call for track_ctc_data:\n",
    "# (replace with cache directory on your machine)\n",
    "# $ micro_sam.image_series_annotator -i /home/pape/.cache/micro_sam/sample_data/image-series.zip.unzip/series/ -e /home/pape/.cache/micro_sam/embeddings/series-embeddings/ -o segmentation_results\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:34:16.878856Z",
     "start_time": "2024-06-22T14:30:13.584739Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'for encoding in encodings:\\n    with torch.no_grad():\\n        segmentation = model.decode(encoding)  # Replace with the actual decoding function\\n        segmentations.append(segmentation)'"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentations = []\n",
    "embed_dir_path = os.path.join(EMBEDDING_CACHE, 'series-embeddings')\n",
    "encoding_files = os.listdir(embed_dir_path)\n",
    "for file in encoding_files:\n",
    "    segmentations.append(zarr.open(os.path.join(embed_dir_path, file), mode='r'))#['encodings'][:])\n",
    "'''for encoding in encodings:\n",
    "    with torch.no_grad():\n",
    "        segmentation = model.decode(encoding)  # Replace with the actual decoding function\n",
    "        segmentations.append(segmentation)'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:58:57.818524Z",
     "start_time": "2024-06-22T14:58:57.810161Z"
    }
   },
   "id": "fe382ec068cef717",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['20120913 exp3 x2_5 stream00716.zarr',\n '20120913 exp3 x2_5 stream00717.zarr',\n '20120913 exp3 x2_5 stream00718.zarr',\n '20120913 exp3 x2_5 stream00719.zarr',\n '20120913 exp3 x2_5 stream00720.zarr']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(os.path.join(EMBEDDING_CACHE,ile))\n",
    "os.listdir(os.path.join(EMBEDDING_CACHE, 'series-embeddings'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:51:21.133654Z",
     "start_time": "2024-06-22T14:51:21.130019Z"
    }
   },
   "id": "21777c1bb55f3af1",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "t = 0\n",
    "embedding_path = os.path.join(embed_dir_path,encoding_files[t])\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "annotator_2d(image, embedding_path, model_type=model_type)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T14:59:37.740126Z",
     "start_time": "2024-06-22T14:59:37.736895Z"
    }
   },
   "id": "88438de1a436e235",
   "execution_count": 32
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
